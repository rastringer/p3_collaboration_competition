{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the third project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from collections import deque\n",
    "from ddpg_agent import Agent\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1060'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_GPU = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "check_GPU\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Tennis.app\"`\n",
    "- **Windows** (x86): `\"path/to/Tennis_Windows_x86/Tennis.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Tennis_Windows_x86_64/Tennis.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Tennis_Linux/Tennis.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Tennis_Linux/Tennis.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Tennis.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Tennis.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"./Tennis_Windows_x86_64/Tennis.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, two agents control rackets to bounce a ball over a net. If an agent hits the ball over the net, it receives a reward of +0.1.  If an agent lets a ball hit the ground or hits the ball out of bounds, it receives a reward of -0.01.  Thus, the goal of each agent is to keep the ball in play.\n",
    "\n",
    "The observation space consists of 8 variables corresponding to the position and velocity of the ball and racket. Two continuous actions are available, corresponding to movement toward (or away from) the net, and jumping. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.65278625 -1.5\n",
      " -0.          0.          6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(state_size, action_size, num_agents=num_agents, random_seed=0)\n",
    "\n",
    "\n",
    "def ddpg(n_episodes=10000, max_t=1000, print_every=100, train=True):\n",
    "    scores_window = deque(maxlen=100)\n",
    "    scores = []\n",
    "    \n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]   \n",
    "        num_agents = len(env_info.agents)\n",
    "        states = env_info.vector_observations\n",
    "        scores_t = np.zeros(num_agents)\n",
    "        agent.reset()\n",
    "        \n",
    "        for t in range(max_t):            \n",
    "            #actions = agent.act(states if train else np.zeros(states.size()))\n",
    "            actions = agent.act(states, i_episode)\n",
    "            env_info = env.step(actions)[brain_name]            \n",
    "            next_states = env_info.vector_observations\n",
    "            rewards = env_info.rewards\n",
    "            dones = env_info.local_done\n",
    "            \n",
    "            if train:\n",
    "                agent.step(states, actions, rewards, next_states, dones, t)\n",
    "                states = next_states\n",
    "                scores_t += np.array(rewards)\n",
    "            if np.any(dones):\n",
    "                break\n",
    "        \n",
    "        score = np.mean(scores_t)   \n",
    "        scores_window.append(score)\n",
    "        avg_score = np.mean(scores_window)\n",
    "        scores.append(score)\n",
    "     \n",
    "\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}\\tMean current: {:.2f}'.format(i_episode, avg_score, score), end=\"\")\n",
    "        torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "        torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "        if i_episode % 5 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, avg_score))\n",
    "        if avg_score >= 0.5:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode, avg_score))\n",
    "            torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "            break\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 5\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 10\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 15\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 20\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 25\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 30\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 35\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 40\tAverage Score: 0.00\tMean current: 0.0550\n",
      "Episode 45\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 50\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 55\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 60\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 65\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 70\tAverage Score: 0.00\tMean current: -0.000\n",
      "Episode 75\tAverage Score: 0.00\tMean current: -0.00\n",
      "Episode 80\tAverage Score: 0.00\tMean current: -0.00\n",
      "Episode 85\tAverage Score: 0.00\tMean current: -0.00\n",
      "Episode 90\tAverage Score: 0.00\tMean current: -0.00\n",
      "Episode 95\tAverage Score: 0.00\tMean current: 0.050\n",
      "Episode 100\tAverage Score: 0.01\tMean current: 0.15\n",
      "Episode 105\tAverage Score: 0.01\tMean current: -0.00\n",
      "Episode 110\tAverage Score: 0.01\tMean current: 0.050\n",
      "Episode 115\tAverage Score: 0.01\tMean current: -0.00\n",
      "Episode 120\tAverage Score: 0.01\tMean current: -0.00\n",
      "Episode 125\tAverage Score: 0.01\tMean current: -0.00\n",
      "Episode 130\tAverage Score: 0.01\tMean current: -0.00\n",
      "Episode 135\tAverage Score: 0.01\tMean current: -0.00\n",
      "Episode 140\tAverage Score: 0.01\tMean current: -0.00\n",
      "Episode 145\tAverage Score: 0.01\tMean current: -0.00\n",
      "Episode 150\tAverage Score: 0.01\tMean current: -0.00\n",
      "Episode 155\tAverage Score: 0.01\tMean current: -0.00\n",
      "Episode 160\tAverage Score: 0.01\tMean current: -0.00\n",
      "Episode 165\tAverage Score: 0.01\tMean current: -0.00\n",
      "Episode 170\tAverage Score: 0.01\tMean current: -0.00\n",
      "Episode 175\tAverage Score: 0.01\tMean current: -0.00\n",
      "Episode 180\tAverage Score: 0.01\tMean current: -0.00\n",
      "Episode 185\tAverage Score: 0.01\tMean current: -0.00\n",
      "Episode 190\tAverage Score: 0.01\tMean current: -0.00\n",
      "Episode 195\tAverage Score: 0.01\tMean current: -0.00\n",
      "Episode 200\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 205\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 210\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 215\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 220\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 225\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 230\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 235\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 240\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 245\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 250\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 255\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 260\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 265\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 270\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 275\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 280\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 285\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 290\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 295\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 300\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 305\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 310\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 315\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 320\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 325\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 330\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 335\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 340\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 345\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 350\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 355\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 360\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 365\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 370\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 375\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 380\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 385\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 390\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 395\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 400\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 405\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 410\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 415\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 420\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 425\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 430\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 435\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 440\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 445\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 450\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 455\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 460\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 465\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 470\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 475\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 480\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 485\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 490\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 495\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 500\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 505\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 510\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 515\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 520\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 525\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 530\tAverage Score: -0.00\tMean current: 0.050\n",
      "Episode 535\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 540\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 545\tAverage Score: -0.00\tMean current: 0.050\n",
      "Episode 550\tAverage Score: -0.00\tMean current: -0.00\n",
      "Episode 555\tAverage Score: 0.00\tMean current: -0.000\n",
      "Episode 560\tAverage Score: 0.00\tMean current: 0.050\n",
      "Episode 565\tAverage Score: 0.00\tMean current: 0.050\n",
      "Episode 570\tAverage Score: 0.00\tMean current: -0.00\n",
      "Episode 575\tAverage Score: 0.00\tMean current: -0.00\n",
      "Episode 580\tAverage Score: 0.00\tMean current: -0.00\n",
      "Episode 585\tAverage Score: 0.01\tMean current: 0.150\n",
      "Episode 590\tAverage Score: 0.01\tMean current: 0.200\n",
      "Episode 595\tAverage Score: 0.01\tMean current: 0.05\n",
      "Episode 600\tAverage Score: 0.02\tMean current: 0.10\n",
      "Episode 605\tAverage Score: 0.02\tMean current: 0.10\n",
      "Episode 610\tAverage Score: 0.03\tMean current: 0.05\n",
      "Episode 615\tAverage Score: 0.03\tMean current: 0.050\n",
      "Episode 620\tAverage Score: 0.03\tMean current: 0.05\n",
      "Episode 625\tAverage Score: 0.04\tMean current: 0.05\n",
      "Episode 630\tAverage Score: 0.04\tMean current: 0.050\n",
      "Episode 635\tAverage Score: 0.04\tMean current: 0.05\n",
      "Episode 640\tAverage Score: 0.05\tMean current: 0.05\n",
      "Episode 645\tAverage Score: 0.06\tMean current: 0.200\n",
      "Episode 650\tAverage Score: 0.06\tMean current: 0.15\n",
      "Episode 655\tAverage Score: 0.07\tMean current: -0.00\n",
      "Episode 660\tAverage Score: 0.07\tMean current: 0.15\n",
      "Episode 665\tAverage Score: 0.08\tMean current: 0.25\n",
      "Episode 670\tAverage Score: 0.08\tMean current: 0.20\n",
      "Episode 675\tAverage Score: 0.09\tMean current: 0.20\n",
      "Episode 680\tAverage Score: 0.10\tMean current: 0.30\n",
      "Episode 685\tAverage Score: 0.11\tMean current: 0.20\n",
      "Episode 690\tAverage Score: 0.11\tMean current: 0.250\n",
      "Episode 695\tAverage Score: 0.11\tMean current: -0.00\n",
      "Episode 700\tAverage Score: 0.14\tMean current: 2.600\n",
      "Episode 705\tAverage Score: 0.20\tMean current: 1.00\n",
      "Episode 710\tAverage Score: 0.20\tMean current: 0.10\n",
      "Episode 715\tAverage Score: 0.20\tMean current: 0.450\n",
      "Episode 720\tAverage Score: 0.20\tMean current: 0.05\n",
      "Episode 725\tAverage Score: 0.20\tMean current: 0.05\n",
      "Episode 730\tAverage Score: 0.20\tMean current: 0.05\n",
      "Episode 735\tAverage Score: 0.20\tMean current: 0.05\n",
      "Episode 740\tAverage Score: 0.20\tMean current: -0.00\n",
      "Episode 745\tAverage Score: 0.19\tMean current: 0.15\n",
      "Episode 750\tAverage Score: 0.19\tMean current: 0.15\n",
      "Episode 755\tAverage Score: 0.19\tMean current: 0.25\n",
      "Episode 760\tAverage Score: 0.19\tMean current: 0.050\n",
      "Episode 765\tAverage Score: 0.18\tMean current: 0.150\n",
      "Episode 770\tAverage Score: 0.19\tMean current: 0.55\n",
      "Episode 775\tAverage Score: 0.19\tMean current: 0.150\n",
      "Episode 780\tAverage Score: 0.19\tMean current: 0.15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 785\tAverage Score: 0.17\tMean current: 0.10\n",
      "Episode 790\tAverage Score: 0.18\tMean current: 0.30\n",
      "Episode 795\tAverage Score: 0.18\tMean current: 0.05\n",
      "Episode 800\tAverage Score: 0.15\tMean current: 0.25\n",
      "Episode 805\tAverage Score: 0.10\tMean current: 0.05\n",
      "Episode 810\tAverage Score: 0.11\tMean current: 0.15\n",
      "Episode 815\tAverage Score: 0.17\tMean current: 1.95\n",
      "Episode 820\tAverage Score: 0.20\tMean current: 0.05\n",
      "Episode 825\tAverage Score: 0.20\tMean current: 0.05\n",
      "Episode 830\tAverage Score: 0.23\tMean current: 0.05\n",
      "Episode 835\tAverage Score: 0.26\tMean current: 0.60\n",
      "Episode 840\tAverage Score: 0.28\tMean current: 1.10\n",
      "Episode 845\tAverage Score: 0.30\tMean current: 0.35\n",
      "Episode 850\tAverage Score: 0.31\tMean current: 0.15\n",
      "Episode 855\tAverage Score: 0.35\tMean current: 0.15\n",
      "Episode 860\tAverage Score: 0.36\tMean current: 0.05\n",
      "Episode 865\tAverage Score: 0.38\tMean current: 0.85\n",
      "Episode 870\tAverage Score: 0.45\tMean current: 2.60\n",
      "Episode 875\tAverage Score: 0.47\tMean current: 0.05\n",
      "Episode 878\tAverage Score: 0.50\tMean current: 2.60\n",
      "Environment solved in 878 episodes!\tAverage Score: 0.50\n"
     ]
    }
   ],
   "source": [
    "scores = ddpg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trained_agent():\n",
    "    n_episodes = 1000\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=False)[brain_name]   \n",
    "        num_agents = len(env_info.agents)\n",
    "        states = env_info.vector_observations\n",
    "        scores_t = np.zeros(num_agents)\n",
    "        agent.reset()\n",
    "    \n",
    "    for t in range(1000):            \n",
    "        #actions = agent.act(states if train else np.zeros(states.size()))\n",
    "        actions = agent.act(states, i_episode)\n",
    "        env_info = env.step(actions)[brain_name]            \n",
    "        next_states = env_info.vector_observations\n",
    "        rewards = env_info.rewards\n",
    "        dones = env_info.local_done\n",
    "        if any(dones):\n",
    "            break \n",
    "            \n",
    "run_trained_agent()\n",
    "\n",
    "env.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
